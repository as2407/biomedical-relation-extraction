{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Venkatesh Dharmaraj\\Downloads\\NLP Project\\data.csv\",na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(r\"C:\\Users\\Venkatesh Dharmaraj\\Downloads\\NLP Project\\test_data.csv\",na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178264, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,row in df.iterrows():\n",
    "#     gs,ge=map(int,row['gene_index'][1:-1].split(','))\n",
    "#     ds,dt=map(int,row['disease_index'][1:-1].split(','))\n",
    "#     row['sentence'] = row['sentence'][:gs]+'<GENE> '+row['sentence'][gs:gs+ge]+'</GENE> '+row['sentence'][gs+ge:]\n",
    "#     row['sentence'] = row['sentence'][:ds]+'<DISEASE> '+row['sentence'][ds:ds+dt]+'</DISEASE> '+row['sentence'][ds+dt:]\n",
    "def entity_representation1(df):\n",
    "    for i,row in df.iterrows():\n",
    "        gs,ge=map(int,row['gene_index'][1:-1].split(','))\n",
    "        ds,dt=map(int,row['disease_index'][1:-1].split(','))\n",
    "        row['sentence'] = row['sentence'][:gs]+'@ * gene * '+row['sentence'][gs:gs+ge]+' @'+row['sentence'][gs+ge:]\n",
    "        row['sentence'] = row['sentence'][:ds]+'# ^ disease ^ '+row['sentence'][ds:ds+dt]+' #'+row['sentence'][ds+dt:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_representation2(df):\n",
    "    for i,row in df.iterrows():\n",
    "        gs,ge=map(int,row['gene_index'][1:-1].split(','))\n",
    "        ds,dt=map(int,row['disease_index'][1:-1].split(','))\n",
    "        row['sentence'] = row['sentence'][:gs]+'@ '+row['sentence'][gs:gs+ge]+' @'+row['sentence'][gs+ge:]\n",
    "        row['sentence'] = row['sentence'][:ds]+'# '+row['sentence'][ds:ds+dt]+' #'+row['sentence'][ds+dt:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_representation3(df):\n",
    "    for i,row in df.iterrows():\n",
    "        gs,ge=map(int,row['gene_index'][1:-1].split(','))\n",
    "        ds,dt=map(int,row['disease_index'][1:-1].split(','))\n",
    "        row['sentence'] = row['sentence'][:gs]+'<GENE> '+row['sentence'][gs+ge:]\n",
    "        row['sentence'] = row['sentence'][:ds]+'<DISEASE> '+row['sentence'][ds+dt:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_representation4(df):\n",
    "    for i,row in df.iterrows():\n",
    "        gs,ge=map(int,row['gene_index'][1:-1].split(','))\n",
    "        ds,dt=map(int,row['disease_index'][1:-1].split(','))\n",
    "        row['sentence'] = row['sentence'] +' '+row['sentence'][gs:gs+ge]+' '+row['sentence'][ds:ds+dt]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=entity_representation4(df)\n",
    "test_df=entity_representation4(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Sentence'] = df['sentence']+df['gene']+df['disease']\n",
    "# df=df[df.columns[[3,4]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df= df.rename({'relation': 'Relation'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.columns[[0,3]]]\n",
    "df= df.rename({'relation': 'Relation','sentence':'Sentence'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=test_df[test_df.columns[[0,3]]]\n",
    "test_df= test_df.rename({'relation': 'Relation','sentence':'Sentence'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NA                     122149\n",
       "genomic_alterations     32831\n",
       "biomarker               20145\n",
       "therapeutic              3139\n",
       "Name: Relation, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Relation = df.Relation.replace({'NA':0,\n",
    "                         'genomic_alterations':1,\n",
    "                         'biomarker':2,\n",
    "                         'therapeutic':3,\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.Relation = test_df.Relation.replace({'NA':0,\n",
    "                         'genomic_alterations':1,\n",
    "                         'biomarker':2,\n",
    "                         'therapeutic':3,\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_shuffled = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# # split the shuffled dataframe into train and test sets\n",
    "# train_size = int(len(df_shuffled) * 0.8)\n",
    "# train_df = df_shuffled[:train_size]\n",
    "# test_df = df_shuffled[train_size:]\n",
    "train_df =df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Relation = df1.Relation.replace({0:0,\n",
    "                         1:1,\n",
    "                         2:1,\n",
    "                         3:1,\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    122149\n",
       "1     32831\n",
       "2     20145\n",
       "3      3139\n",
       "Name: Relation, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    122149\n",
       "1     56115\n",
       "Name: Relation, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=train_df[train_df['Relation'] != 0 ].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    32831\n",
       "2    20145\n",
       "3     3139\n",
       "Name: Relation, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(len(df['Sentence'])):\n",
    "  data.append(nltk.word_tokenize(df['Sentence'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vectors(data):\n",
    "    X = []\n",
    "    for review in data:\n",
    "        word_vectors = []\n",
    "        for word in review:\n",
    "            try:\n",
    "                word_vectors.append(model[word])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        if not word_vectors:\n",
    "            X.append(np.zeros(300))\n",
    "        else:\n",
    "            X.append(np.mean(word_vectors, axis=0))\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df['Sentence']\n",
    "y_test =test_df['Relation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect=TfidfVectorizer(ngram_range=(1,2),\n",
    "#                         use_idf=True).fit(df['Sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_vectorized=vect.transform(df1['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_vectorized2=vect.transform(df2['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_tfidf_clf=LinearSVC()\n",
    "# svm_tfidf_clf.fit(X_train_vectorized, df1['Relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_tfidf_clf.fit(X_train_vectorized2, df1['Relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test.replace(2,1)\n",
    "# y_test.replace(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_tfidf_clf2=LinearSVC()\n",
    "# svm_tfidf_clf2.fit(X_train_vectorized2, df2['Relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=[]\n",
    "# for i in X_test:\n",
    "#     pred1 = svm_tfidf_clf.predict(vect.transform([i]))\n",
    "#     if pred1[0]==0:\n",
    "#         y_pred.append(pred1[0])\n",
    "#     else:\n",
    "#         pred2= svm_tfidf_clf2.predict(vect.transform([i]))\n",
    "#         y_pred.append(pred2[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu111/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     print('GPU available:', torch.cuda.get_device_name(0))\n",
    "# else:\n",
    "#     print('No GPU available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.__version__)\n",
    "# print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "  data=[]\n",
    "  for i in range(len(df['Relation'])):\n",
    "    data.append(nltk.word_tokenize(df['Sentence'].iloc[i]))\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df1 = tokenize(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eleven deleterious variants, six nonsense and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In addition, silencing of HLJ1 partially rever...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The identification of ApoB loss-of-function mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In most of the classic Philadelphia-negative M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>We identified a BCR/ABL-dependent increase in ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178243</th>\n",
       "      <td>Inhibition of MIR21, MIR23A, and MIR27A had sy...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178246</th>\n",
       "      <td>Localized overexpression of FGF-2 and BDNF in ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178249</th>\n",
       "      <td>Although patients with PDGFRB rearrangement mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178250</th>\n",
       "      <td>In present study, functional and mechanism exp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178257</th>\n",
       "      <td>In additional, HNSCC tumor tissue was analyzed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56115 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentence  Relation\n",
       "2       Eleven deleterious variants, six nonsense and ...         1\n",
       "8       In addition, silencing of HLJ1 partially rever...         2\n",
       "10      The identification of ApoB loss-of-function mu...         1\n",
       "12      In most of the classic Philadelphia-negative M...         1\n",
       "18      We identified a BCR/ABL-dependent increase in ...         2\n",
       "...                                                   ...       ...\n",
       "178243  Inhibition of MIR21, MIR23A, and MIR27A had sy...         2\n",
       "178246  Localized overexpression of FGF-2 and BDNF in ...         3\n",
       "178249  Although patients with PDGFRB rearrangement mo...         1\n",
       "178250  In present study, functional and mechanism exp...         2\n",
       "178257  In additional, HNSCC tumor tissue was analyzed...         1\n",
       "\n",
       "[56115 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df2 = tokenize(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = tokenize(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vectors_3(data):\n",
    "    inputs = []\n",
    "    for review in data:\n",
    "        review_vecs = []\n",
    "        for i, word in enumerate(review):\n",
    "            # print(word in model)\n",
    "            if i < 20:\n",
    "                if word in model:\n",
    "                    review_vecs.append(model[word])\n",
    "        if len(review_vecs) < 20:\n",
    "            review_vecs += [np.zeros(300)] * (20 - len(review_vecs))\n",
    "        inputs.append(review_vecs)\n",
    "    return np.array(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df1=generate_vectors_3(train_data_df1)\n",
    "X_train_df2=generate_vectors_3(train_data_df2)\n",
    "X_test3=generate_vectors_3(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.lstm(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "              weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "              )\n",
    "        return hidden\n",
    "\n",
    "train_data = X_train_df1\n",
    "train_labels = df1['Relation'].to_numpy()\n",
    "# test_data = X_test3\n",
    "# test_labels = test_df['Relation'].to_numpy()\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_data).float(), torch.from_numpy(train_labels).long())\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)   \n",
    "\n",
    "LSTM_model = LSTMModel(300,40,2,2)\n",
    "optimizer = torch.optim.Adam(LSTM_model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0,1.5]))\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        batch_size = inputs.shape[0]\n",
    "        h = LSTM_model.init_hidden(batch_size)\n",
    "        h = tuple([e.data for e in h])\n",
    "        optimizer.zero_grad()\n",
    "        outputs,h = LSTM_model(inputs,h)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "#  Test the model\n",
    "# with torch.no_grad():\n",
    "#     LSTM_model.eval()\n",
    "#     test_data = torch.from_numpy(test_data).float()\n",
    "#     test_labels = torch.from_numpy(test_labels).long()\n",
    "#     h = LSTM_model.init_hidden(test_data.shape[0])\n",
    "#     outputs,h = LSTM_model(test_data,h)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total = test_labels.size(0)\n",
    "#     correct = (predicted == test_labels).sum().item()\n",
    "#     print(classification_report(predicted,test_labels))\n",
    "\n",
    "#     print('Test Accuracy: {:.2f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel1(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.4):\n",
    "        super(LSTMModel1, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.lstm(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "              weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "              )\n",
    "        return hidden\n",
    "\n",
    "train_data = X_train_df2\n",
    "train_labels = (df2['Relation']-1).to_numpy()\n",
    "# test_data = X_test3\n",
    "# test_labels = test_df['Relation'].to_numpy()\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_data).float(), torch.from_numpy(train_labels).long())\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)   \n",
    "\n",
    "LSTM_model1 = LSTMModel1(300,40,3,2)\n",
    "optimizer = torch.optim.Adam(LSTM_model1.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(torch.tensor([1.0,2.0,4.0]))\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        batch_size = inputs.shape[0]\n",
    "        h = LSTM_model1.init_hidden(batch_size)\n",
    "        h = tuple([e.data for e in h])\n",
    "        optimizer.zero_grad()\n",
    "        outputs,h = LSTM_model1(inputs,h)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "#  Test the model\n",
    "# with torch.no_grad():\n",
    "#     LSTM_model.eval()\n",
    "#     test_data = torch.from_numpy(test_data).float()\n",
    "#     test_labels = torch.from_numpy(test_labels).long()\n",
    "#     h = LSTM_model.init_hidden(test_data.shape[0])\n",
    "#     outputs,h = LSTM_model(test_data,h)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total = test_labels.size(0)\n",
    "#     correct = (predicted == test_labels).sum().item()\n",
    "#     print(classification_report(predicted,test_labels))\n",
    "\n",
    "#     print('Test Accuracy: {:.2f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "LSTM_model.eval()\n",
    "LSTM_model1.eval()\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test3)):\n",
    "        # Predict the class probabilities for each sentence using model1\n",
    "        test_data = torch.from_numpy(X_test3[i:i+1]).float()\n",
    "\n",
    "        h = LSTM_model.init_hidden(test_data.shape[0])\n",
    "        outputs,h = LSTM_model(test_data,h)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # print(predicted[-1])\n",
    "        # y_pred_proba1 = LSTM_model(X_test[i:i+1])\n",
    "\n",
    "        # Apply a threshold to obtain the predicted class label for model1\n",
    "        # threshold = 0.5\n",
    "        # y_pred1 = (y_pred_proba1 >= threshold).int()\n",
    "\n",
    "        # If the predicted class is 0, predict the class label using model2\n",
    "        if predicted[-1] == 1:\n",
    "            # print(predicted[-1])\n",
    "            # y_pred_proba2 = LSTM_model1(X_test[i:i+1])\n",
    "            # y_pred_proba2_softmax = F.softmax(y_pred_proba2, dim=1)\n",
    "            # _, y_pred2 = torch.max(y_pred_proba2_softmax, dim=1)\n",
    "            # test_data = torch.from_numpy(X_test3[i:i+1]).float()\n",
    "\n",
    "            h2 = LSTM_model1.init_hidden(test_data.shape[0])\n",
    "            outputs1,h2 = LSTM_model1(test_data,h2)\n",
    "            _, predicted1 = torch.max(outputs1.data, 1)\n",
    "\n",
    "            y_pred.append(predicted1[-1]+1)\n",
    "            # print(y_pred[-1])\n",
    "        # Otherwise, predict the class label as non-class 0\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "y_pred = np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = y_test.to_numpy()\n",
    "test_labels = torch.from_numpy(test_labels).long()\n",
    "print(classification_report(y_pred,test_labels,digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
